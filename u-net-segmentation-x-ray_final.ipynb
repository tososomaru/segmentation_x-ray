{"cells":[{"metadata":{"trusted":true},"cell_type":"code","source":"import warnings\n\nwarnings.filterwarnings('ignore')","execution_count":null,"outputs":[]},{"metadata":{"id":"UcfYivBTBwQm","outputId":"bba4aa84-c416-4b16-e793-4465743ae27a","trusted":true},"cell_type":"code","source":"#Google Drive\n\n# from google.colab import drive\n# drive.mount(\"/content/drive\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Kaggle\n\n\"\"\"Получить ссылку на архив с общим доступом их гугл диска.\nмежду /d/ и /view? - id для загрузки\n\"\"\"\n\nurl = 'https://drive.google.com/file/...../view?usp=sharing'\n\n\n!conda install -y gdown &> /dev/null\n!gdown --id 1nIywScpYSExIjpCR9tcl3lvwgwJXF8kw","execution_count":null,"outputs":[]},{"metadata":{"id":"XNUj5tIPKEQT","trusted":true},"cell_type":"code","source":"# Перезапустить среду после обновления matplotlib!!\n# Не требуется для kaggle\n# !pip install --upgrade matplotlib &> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"id":"1j0ZN5mZB_WP"},"cell_type":"markdown","source":"# Data Load"},{"metadata":{"id":"jWRUS6VVGeiG","trusted":true},"cell_type":"code","source":"import os\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport pandas as pd\nimport cv2\nimport seaborn as sns\n\nsns.set()","execution_count":null,"outputs":[]},{"metadata":{"id":"S0NKkmA2B-fd","trusted":true},"cell_type":"code","source":"# Google Drive\n# !unzip /content/drive/MyDrive/ml/Chest_Xray_segmentation.zip -d data/ &> /dev/null\n\n# Kaggle\n\n!unzip /kaggle/working/Chest_Xray_segmentation.zip -d data/ &> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"id":"nR_PPvqVCjI6","trusted":true},"cell_type":"code","source":"img_format = '.bmp'\nnew_img_format = '.png'\n\nbase_path = Path('data/SegmChest/')\npathes = ['xray', 'lung', 'ribs', 'col', 'heart'] \nmask_dirs = ['lung', 'ribs', 'col', 'heart']\n\n# train and val folders are for initial data (in .bmp format) - upload your data \n# as a zip archive here in folder \"data\" please\n\n# # preprocessed data will appear here\n(base_path / 'train/masks').mkdir(parents=True, exist_ok=True)\n(base_path / 'val/masks').mkdir(parents=True, exist_ok=True)","execution_count":null,"outputs":[]},{"metadata":{"id":"9trfD-rLC1Dd","trusted":true},"cell_type":"code","source":"train_dir = base_path / 'train'\nvalid_dir = base_path / 'val'","execution_count":null,"outputs":[]},{"metadata":{"id":"7vgWp2ilC6Xb","trusted":true},"cell_type":"code","source":"data = []\nfor cur_dir in [train_dir, valid_dir]:\n    images = sorted(cur_dir.glob('xray/*.bmp'))\n    df = pd.DataFrame(images, columns=['image_path'])\n    masks = pd.DataFrame({d: sorted(cur_dir.glob(f'{d}/*.bmp')) for d in mask_dirs}, columns=mask_dirs)\n    df['mask_path'] = df.image_path.apply(lambda x: str(x).replace('xray', 'masks'))\n    data.append(pd.concat([df, masks], axis=1))\n    \ntrain_data, valid_data = data","execution_count":null,"outputs":[]},{"metadata":{"id":"fzVqCw8LDBSR","outputId":"0db84573-d7a9-407a-e9e3-8843be0f799e","trusted":true},"cell_type":"code","source":"train_data.head(2)","execution_count":null,"outputs":[]},{"metadata":{"id":"pX7AsnJmFI68","trusted":true},"cell_type":"code","source":"train_data.to_csv('train.csv', index=False)\nvalid_data.to_csv('valid.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"id":"UQxwCH2VDrwY"},"cell_type":"markdown","source":"# Data Visualisation"},{"metadata":{"id":"OaTYl-cuDwRE","trusted":true},"cell_type":"code","source":"def plot_images(imgs, names=None, axs=None, show=True, nrows=None, ncols=None, figsize=(8, 4)):\n    from math import ceil\n    if nrows is None and ncols is None:\n        nrows = 1\n        ncols = len(imgs)\n    elif nrows is None:\n        nrows = ceil(len(imgs) / ncols)\n    elif ncols is None:\n        ncols = ceil(len(imgs) / nrows)\n    \n    if axs is None:\n        fig, axs = plt.subplots(ncols=ncols, nrows=nrows, figsize=figsize)\n    if nrows == 1 and ncols == 1:\n        axs.imshow(imgs[0])\n        axs.set_axis_off()\n        if names and len(names) > 0:\n            axs.set_title(names[0], fontsize=15)\n    elif nrows == 1 or ncols == 1:\n        for j, ax in enumerate(axs):\n            ax.imshow(imgs[j])\n            ax.set_axis_off()\n            if names and j < len(names):\n                ax.set_title(names[j], fontsize=15)\n    else:\n        for j, ax in enumerate(axs):\n            for k, sub_ax in enumerate(ax):\n                image_id = j * ncols + k\n                sub_ax.set_axis_off()\n                if image_id < len(imgs):\n                    sub_ax.imshow(imgs[image_id])\n                    if names and image_id < len(names):\n                        sub_ax.set_title(names[image_id], fontsize=15)\n    if show:\n        plt.show()","execution_count":null,"outputs":[]},{"metadata":{"id":"07-M_m_PDx-7","trusted":true},"cell_type":"code","source":"# Merge the mask images\n\ndef merge_masks(data_frame, plot_sample=False):  \n    for record in data_frame.iloc:\n        lungs_mask = np.array(Image.open(record.lung))\n        ribs_mask = np.array(Image.open(record.ribs))\n        col_mask = np.array(Image.open(record.col))\n        heart_mask = np.array(Image.open(record.heart))\n        \n        mask = (lungs_mask > 0).astype('uint8')\n        mask[ribs_mask > 0] = 2\n        mask[col_mask > 0] = 3\n        mask[heart_mask > 0] = 4\n        \n        if plot_sample:\n            plot_images([mask])\n    \n        Image.fromarray(mask).save(record.mask_path)","execution_count":null,"outputs":[]},{"metadata":{"id":"Ru33zZhEDz1x","trusted":true},"cell_type":"code","source":"merge_masks(train_data)","execution_count":null,"outputs":[]},{"metadata":{"id":"fvmf4D3qD2Z4","outputId":"9aac82b2-1825-4356-b4e0-259d8d1430b1","trusted":true},"cell_type":"code","source":"merge_masks(valid_data, True)","execution_count":null,"outputs":[]},{"metadata":{"id":"JFe7ulwAFMlC"},"cell_type":"markdown","source":"# Create DataLoader"},{"metadata":{"id":"uM1mkg4UFPml","trusted":true},"cell_type":"code","source":"import matplotlib.pyplot as plt\nimport numpy as np\nimport cv2\nimport pandas as pd\nimport imageio\n\nfrom PIL import Image\nfrom statistics import stdev \nfrom sklearn.model_selection import train_test_split\nimport torch","execution_count":null,"outputs":[]},{"metadata":{"id":"4abFu1yoFRRK","trusted":true},"cell_type":"code","source":"from torch.utils.data import DataLoader\nfrom torch.utils.data import Dataset as BaseDataset","execution_count":null,"outputs":[]},{"metadata":{"id":"lX1x2qc1FSsK","trusted":true},"cell_type":"code","source":"class Dataset(BaseDataset):\n    \"\"\"Chest Xray Dataset. Read images, apply augmentation and preprocessing transformations.\n    \n    Args:\n        images_dir (str): path to csv with all image and mask paths\n        augmentation (albumentations.Compose): data transfromation pipeline \n            (e.g. flip, scale, etc.)\n        preprocessing (albumentations.Compose): data preprocessing \n            (e.g. noralization, shape manipulation, etc.)\n    \n    \"\"\"\n    \n    def __init__(\n            self,\n            path_to_csv,\n            augmentation=None, \n            preprocessing=None,\n    ):\n        self.df = pd.read_csv(path_to_csv)\n        \n        self.augmentation = augmentation\n        self.preprocessing = preprocessing\n    \n    def __getitem__(self, i):\n        record = self.df.iloc[i]\n        \n        sample = {'image': cv2.imread(record.image_path, 0)[..., None], \n                  'mask': cv2.imread(record.mask_path, 0).astype('float')}\n        \n        if self.augmentation:\n            sample = self.augmentation(**sample)\n        \n        if self.preprocessing:\n            sample = self.preprocessing(**sample)\n            masks = [(sample['mask'] == v) for v in range(len(mask_dirs) + 1)]\n            sample['mask'] = torch.stack(masks).type(torch.float)\n            \n        return sample['image'], sample['mask']\n        \n    def __len__(self):\n        return self.df.shape[0]","execution_count":null,"outputs":[]},{"metadata":{"id":"NBuvZ2mdFX8-","trusted":true},"cell_type":"code","source":"!pip install git+https://github.com/albumentations-team/albumentations.git &> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"id":"MAWN1ONbF0S7","trusted":true},"cell_type":"code","source":"import albumentations as albu\nfrom albumentations.pytorch.transforms import ToTensorV2","execution_count":null,"outputs":[]},{"metadata":{"id":"81p6gERAGHTH","outputId":"f6458ce3-5eb6-4d39-d966-8d7d949a6e9a","trusted":true},"cell_type":"code","source":"height = 512\nwidth = 512\n\naugmentations = albu.Compose([\n    albu.HorizontalFlip(),\n    albu.OneOf([\n        albu.RandomContrast(),\n        albu.RandomGamma(),\n        albu.RandomBrightness(),\n    ], p=0.3),\n    albu.OneOf([\n        albu.ElasticTransform(),\n        albu.GridDistortion(),\n        albu.OpticalDistortion(),\n    ]),\n    albu.PadIfNeeded(height, width),\n    albu.RandomSizedCrop(min_max_height=[int(height/8*7), height], \n                    height=height, width=width)\n])\n\npreprocessing = albu.Compose([\n    albu.Resize(height, width),\n    albu.Normalize([0.5], [0.5]),\n    ToTensorV2()\n])\n\ntrain_dataset = Dataset('train.csv', augmentation=augmentations, preprocessing=preprocessing)\nvalid_dataset = Dataset('valid.csv', preprocessing=preprocessing)\n\ntrain_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)\nvalid_loader = DataLoader(valid_dataset, batch_size=1, shuffle=False)\n\n#added\nloaders = {\n    'train' : train_loader,\n    'valid' : valid_loader\n}","execution_count":null,"outputs":[]},{"metadata":{"id":"iHnlx8ZaGNWD","outputId":"4530005b-4a98-4dc4-9c58-e407fda89183","trusted":true},"cell_type":"code","source":"dataset = Dataset('train.csv', augmentation=augmentations)\n\nfor i in range(4):\n    sample = dataset[i] # get some sample\n    plot_images(sample, names=['Image', 'Mask'])","execution_count":null,"outputs":[]},{"metadata":{"id":"RFxGJPDFKjY5"},"cell_type":"markdown","source":"# Create and train model"},{"metadata":{"id":"qSPDouD2Kod_","trusted":true},"cell_type":"code","source":"#added \n!pip install segmentation_models_pytorch &> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"!pip install catalyst==21.03 &> /dev/null","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from catalyst.callbacks.metrics.segmentation import (DiceCallback,\n                                               IOUCallback)\nfrom catalyst.callbacks.misc import EarlyStoppingCallback\nfrom catalyst.callbacks.metrics.confusion_matrix import ConfusionMatrixCallback\nfrom catalyst.callbacks.optimizer import OptimizerCallback\n\nfrom catalyst.dl import SupervisedRunner\n\nfrom catalyst.contrib.nn import OneCycleLRWithWarmup\nfrom catalyst.contrib.nn.criterion.dice import DiceLoss\nfrom catalyst.contrib.nn.optimizers.radam import RAdam\n\nimport torch\nimport numpy as np\nimport segmentation_models_pytorch as smp","execution_count":null,"outputs":[]},{"metadata":{"id":"CPkFRw5lKuoU","outputId":"09989589-41db-42e5-9095-111358302304","trusted":true},"cell_type":"code","source":"encoder_name = 'timm-efficientnet-b0'\nactivation = 'softmax2d' # could be None for logits or 'softmax2d' for multicalss segmentation\ndevice = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n\n#added classes\nclasses = ['lung', 'ribs', 'col', 'heart', 'xray']\n\n# create segmentation model with pretrained encoder\nmodel = smp.Unet(\n    encoder_name=encoder_name,\n    classes=len(classes), \n    activation=activation,\n    in_channels=1,\n)","execution_count":null,"outputs":[]},{"metadata":{"id":"7wi7ebDhTTeG","trusted":true},"cell_type":"code","source":"\n\"\"\"\nIOUCallback - обратный вызов метрики iou (сохраняет метрику для каждого класса/модели)\n\nEarlyStoppingCallback - останаливает обучение, если после 'patience' эпох не происходит \nулучшения метрики 'metric_key' на основе валидации 'loader_key'\n\nOptimizerCallback - обратный вызов оптимизатора (сохранение функции потерь)\n\nConfusionMatrixCallback - обратный вызов для матрицы ошибок.\n\"\"\"\n\ncallbacks = [\n    IOUCallback(input_key=\"logits\", target_key=\"targets\",\n                threshold=0.5, class_names=classes),\n    OptimizerCallback(metric_key='loss'),\n    EarlyStoppingCallback(patience=5,loader_key='valid', \n                          metric_key='iou', minimize=False),\n    DiceCallback(input_key=\"logits\", target_key=\"targets\", \n                 class_names=classes)\n]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"from torch.optim.lr_scheduler import StepLR","execution_count":null,"outputs":[]},{"metadata":{"id":"MiRbuEvQ9nKx","trusted":true},"cell_type":"code","source":"num_epochs = 50\nlearning_rate = 1e-4\n\n\n# Критерий - функция потерь\ncritetion = DiceLoss()\n\n\n# metrics = [\n#     smp.utils.metrics.IoU(threshold=0.5),\n# ]\n\n\"\"\"\nВариант оптимизатора Adam, адаптивная \nскорость обучения которого выпрямлена.\n\"\"\"\n\noptimizer = RAdam([ \n    dict(params=model.parameters(), lr=0.0001),\n])\n\n\"\"\"\nscheduler - планировщик из pytorch'a. Снижает скорость обучения по формуле :\nlr = lr * gamma. Снижение происходит с шагом \"step_size\".\n\nДо этого lr был 1e-4 и резо снижался на 25 эпохе в 10 раз.\nТеперь lr плавно снижается с 1e-4 до 1e-5. gamma можно крутить\nи менять темп изменения lr.\n\"\"\"\n\nscheduler = StepLR(\n    optimizer,\n    step_size=1,\n    gamma=0.956\n)\n\n\"\"\"Планировщик из catalyst. Интересная штука, можно изучить.\"\"\"\n\n# scheduler = OneCycleLRWithWarmup(\n#     optimizer, \n#     num_steps=num_epochs, \n#     lr_range=(1e-4, 1e-5),\n#     init_lr = learning_rate,\n#     warmup_steps=2\n# )","execution_count":null,"outputs":[]},{"metadata":{"id":"IU7L_Vkt-lDK","outputId":"ed47c686-b0e2-449c-a8ea-a2192d04d029","trusted":true},"cell_type":"code","source":"#added\n#\nlogdir = \"./logs\"\n\n\"\"\"\n\nОбучение модели \"пайплайном\". Меньше циклов, красивее и читабельнее\nкод. \n\nДля обучения передаются модель, функция ошибки, оптимайзер,\nпланировщик, обратные вызовы, загрузчик (с датасетами), путь для\nлоггирования, кол-во эпох, датасет в загрузчике для валидации,\nметрика для валидации,флаг для отключение минимизации IOU и флаг\nдля вывода в консоль процесса обучения.\n\n\"\"\"\nrunner = SupervisedRunner()\n\n\nrunner.train(\n    model=model,\n    criterion=critetion,\n    optimizer=optimizer,\n    scheduler=scheduler,\n    callbacks=callbacks,\n    loaders=loaders,\n    logdir=logdir,\n    num_epochs=num_epochs,\n    valid_loader=\"valid\",\n    valid_metric=\"iou\",\n    minimize_valid_metric=False,\n    verbose=True\n)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Tensorboard"},{"metadata":{"trusted":true},"cell_type":"code","source":"def create_heatmap(data):\n    fig = plt.figure(figsize=(12, 12))\n    heatmap = sns.heatmap(data, annot=True, cbar=False)\n    heatmap.yaxis.set_ticklabels(heatmap.yaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n    heatmap.xaxis.set_ticklabels(heatmap.xaxis.get_ticklabels(), rotation=0, ha='right', fontsize=12)\n    heatmap.set(ylabel='Predicted Class', xlabel='Actual Class', title=\"Матрица ошибок по классам\")\n    plt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = Dataset('valid.csv')\n\n# Последняя строка и последний столбец это суммы \n# по столбцам и по строкам\n\nmatrix_for_classes = np.zeros(shape=(6, 6))\n\nfor image, mask in dataset:\n    sample = preprocessing(image=image, mask=mask)\n    image_tensor = sample['image']\n    mask = sample['mask']\n    \n    prediction = model(image_tensor[None, ...].to(device)).argmax(dim=1)\n    pred = prediction.cpu().numpy()[0]\n    act = mask[None, ...].cpu().numpy().reshape((512, 512))\n\n    for i in range(pred.shape[0]):\n        for n in range(pred.shape[1]):\n\n            matrix_for_classes[int(act[i, n]), int(pred[i, n])] += 1\n\nfor i in range(0, 5):\n    matrix_for_classes[5:,i] = np.sum(matrix_for_classes[:5, i])\n    matrix_for_classes[i,5:] = np.sum(matrix_for_classes[i, :5])\n  \n\ncreate_heatmap(matrix_for_classes)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Архитектура сети\nfrom catalyst import dl, utils\nfeatures_batch = next(iter(loaders[\"valid\"]))[0]\nutils.trace_model(model=runner.model, batch=features_batch.cuda())","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"Kaggle\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"\n\"\"\"\nСледующую ячейку лучше не запускать сразу с этой.\nМожет появться ошибка.\n\"\"\"\n\n!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-amd64.zip &> /dev/null\n!unzip ngrok-stable-linux-amd64.zip &> /dev/null\n\n# Run tensorboard as well as Ngrox (for tunneling as non-blocking processes)\nimport os\nimport multiprocessing\n\n\npool = multiprocessing.Pool(processes = 10)\nresults_of_processes = [pool.apply_async(os.system, args=(cmd, ), callback = None )\n                        for cmd in [\n                        f\"tensorboard --logdir ./logs/ --host 0.0.0.0 --port 6006 &\",\n                        \"./ngrok http 6006 &\"\n                        ]]","execution_count":1,"outputs":[{"output_type":"stream","text":"^C\r\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# Tensorboard\n\n\"\"\"\nПо ссылке на 'доске'доступны все графики по метрикам \nдля классов, модели, ошибки, изменения скорости обучения и т.д.\n\"\"\"\n\n! curl -s http://localhost:4040/api/tunnels | python3 -c \\\n    \"import sys, json; print(json.load(sys.stdin)['tunnels'][0]['public_url'])\"","execution_count":2,"outputs":[{"output_type":"stream","text":"https://5aaa3e490109.ngrok.io\r\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"Google Drive"},{"metadata":{"trusted":true},"cell_type":"code","source":"%load_ext tensorboard","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"%tensorboard --logdir logs","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Save and Load Model"},{"metadata":{"trusted":true},"cell_type":"code","source":"# Save model (Google Drive)\nPATH = \"/content/drive/MyDrive/\"\n\n# Kaggle\n\ntorch.save(runner.model, \"model.pth\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"#Load model\nmodel = torch.load(\"model.pth\")","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Test model"},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = Dataset('valid.csv')\n\nfor image, mask in dataset:\n    sample = preprocessing(image=image, mask=mask)\n    image_tensor = sample['image']\n    mask = sample['mask']\n    \n    prediction = model(image_tensor[None, ...].to(device)).argmax(dim=1)\n    prediction = prediction.cpu().numpy()[0]\n    \n    \n    plot_images([image, mask, prediction], names=['Image', 'Mask', 'Predicted Mask'])\n    ","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.9","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}